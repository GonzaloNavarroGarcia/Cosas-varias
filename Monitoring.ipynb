{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ff4933",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def calculate_psi_continuous(df1, df2, column, bins=10, fill_value=1):\n",
    "    \"\"\"\n",
    "    Calculate the Population Stability Index (PSI) for a continuous column using binning based on the first DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    - df1: First pandas DataFrame representing the first period.\n",
    "    - df2: Second pandas DataFrame representing the second period.\n",
    "    - column: The name of the continuous column to analyze.\n",
    "    - bins: Number of bins to divide the data (default is 10).\n",
    "    - fill_value: The value to replace zero counts with (default is 1).\n",
    "\n",
    "    Returns:\n",
    "    - psi_total: The total PSI value.\n",
    "    - psi_df: A pandas DataFrame showing the bin ranges, count, percentage, and PSI contribution for each bin.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create bin edges based on the first DataFrame only (reference period)\n",
    "    bin_edges = np.histogram_bin_edges(df1[column], bins=bins)\n",
    "    \n",
    "    # Count occurrences in each bin for both periods\n",
    "    df1_counts, _ = np.histogram(df1[column], bins=bin_edges)\n",
    "    df2_counts, _ = np.histogram(df2[column], bins=bin_edges)\n",
    "    \n",
    "    # Convert counts to percentages (relative frequencies)\n",
    "    df1_pct = df1_counts / len(df1)\n",
    "    df2_pct = df2_counts / len(df2)\n",
    "    \n",
    "    # Replace zero entries with the specified fill_value\n",
    "    df1_pct = np.where(df1_pct == 0, fill_value, df1_pct)\n",
    "    df2_pct = np.where(df2_pct == 0, fill_value, df2_pct)\n",
    "    \n",
    "    # Calculate the PSI contribution for each bin\n",
    "    psi_contributions = (df2_pct - df1_pct) * np.log(df2_pct / df1_pct)\n",
    "    \n",
    "    # Create a DataFrame with detailed PSI information for each bin\n",
    "    psi_df = pd.DataFrame({\n",
    "        'Bin_start': bin_edges[:-1],\n",
    "        'Bin_end': bin_edges[1:],\n",
    "        'Period1_count': df1_counts,\n",
    "        'Period1_pct': df1_pct,\n",
    "        'Period2_count': df2_counts,\n",
    "        'Period2_pct': df2_pct,\n",
    "        'PSI_contribution': psi_contributions\n",
    "    })\n",
    "    \n",
    "    # Calculate the total PSI\n",
    "    psi_total = np.sum(psi_contributions)\n",
    "    \n",
    "    return psi_total, psi_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037e2db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def calculate_psi_categorical(df1, df2, column, fill_value=1):\n",
    "    \"\"\"\n",
    "    Calculate the Population Stability Index (PSI) for a categorical column.\n",
    "    \n",
    "    Parameters:\n",
    "    - df1: First pandas DataFrame representing the first period.\n",
    "    - df2: Second pandas DataFrame representing the second period.\n",
    "    - column: The name of the categorical column to analyze.\n",
    "    - fill_value: The value to replace zero counts with (default is 1).\n",
    "\n",
    "    Returns:\n",
    "    - psi_total: The total PSI value.\n",
    "    - psi_df: A pandas DataFrame showing the count, percentage, and PSI contribution for each category.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Count the occurrences for each category in both periods\n",
    "    df1_counts = df1[column].value_counts(normalize=False)\n",
    "    df2_counts = df2[column].value_counts(normalize=False)\n",
    "    \n",
    "    # Convert counts to percentages (relative frequencies)\n",
    "    df1_pct = df1_counts / len(df1)\n",
    "    df2_pct = df2_counts / len(df2)\n",
    "    \n",
    "    # Ensure all categories are present in both periods\n",
    "    all_categories = pd.Index(df1_counts.index).union(df2_counts.index)\n",
    "    df1_pct = df1_pct.reindex(all_categories, fill_value=0)\n",
    "    df2_pct = df2_pct.reindex(all_categories, fill_value=0)\n",
    "    \n",
    "    # Replace zero entries with the specified fill_value\n",
    "    df1_pct = np.where(df1_pct == 0, fill_value, df1_pct)\n",
    "    df2_pct = np.where(df2_pct == 0, fill_value, df2_pct)\n",
    "    \n",
    "    # Calculate the PSI contribution for each category\n",
    "    psi_contributions = (df2_pct - df1_pct) * np.log(df2_pct / df1_pct)\n",
    "    \n",
    "    # Create a DataFrame with detailed PSI information for each category\n",
    "    psi_df = pd.DataFrame({\n",
    "        'Category': all_categories,\n",
    "        'Period1_count': df1_counts.reindex(all_categories, fill_value=0),\n",
    "        'Period1_pct': df1_pct,\n",
    "        'Period2_count': df2_counts.reindex(all_categories, fill_value=0),\n",
    "        'Period2_pct': df2_pct,\n",
    "        'PSI_contribution': psi_contributions\n",
    "    })\n",
    "    \n",
    "    # Calculate the total PSI\n",
    "    psi_total = np.sum(psi_contributions)\n",
    "    \n",
    "    return psi_total, psi_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8750b9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def calculate_hhi(df, column):\n",
    "    \"\"\"\n",
    "    Calculate the Herfindahl-Hirschman Index (HHI) for a categorical column to assess concentration.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: pandas DataFrame containing the data.\n",
    "    - column: The name of the categorical column to analyze.\n",
    "\n",
    "    Returns:\n",
    "    - hhi_value: The Herfindahl-Hirschman Index (HHI) value.\n",
    "    - hhi_df: A pandas DataFrame showing the count, percentage, and squared percentage for each category.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Count the occurrences for each category\n",
    "    counts = df[column].value_counts(normalize=False)\n",
    "    \n",
    "    # Convert counts to percentages (relative frequencies)\n",
    "    pct = counts / len(df)\n",
    "    \n",
    "    # Calculate the squared percentage (used in HHI)\n",
    "    squared_pct = pct ** 2\n",
    "    \n",
    "    # Calculate the HHI as the sum of squared percentages\n",
    "    hhi_value = np.sum(squared_pct)\n",
    "    \n",
    "    # Create a DataFrame with detailed HHI information for each category\n",
    "    hhi_df = pd.DataFrame({\n",
    "        'Category': counts.index,\n",
    "        'Count': counts.values,\n",
    "        'Percentage': pct.values,\n",
    "        'Squared_Percentage': squared_pct.values\n",
    "    })\n",
    "    \n",
    "    return hhi_value, hhi_df\n",
    "\n",
    "# Example usage:\n",
    "# hhi_value, hhi_detail_df = calculate_hhi(df, 'city_column')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4ed4dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gonza\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.4)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-dd5dd4a97216>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;31m# Assuming df1 and df2 are your DataFrames and 'value' and 'category' are the respective columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m \u001b[0mks_stat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mks_p_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkolmogorov_smirnov_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'value'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m \u001b[0mchi2_stat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchi2_p_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchi_square_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'category'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[0mmae\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalculate_mae\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'value'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df1' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ks_2samp, chi2_contingency\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# 1. Kolmogorov-Smirnov Test (KS)\n",
    "def kolmogorov_smirnov_test(df1, df2, column):\n",
    "    \"\"\"\n",
    "    Perform the Kolmogorov-Smirnov test to compare the distribution of values in two DataFrames.\n",
    "\n",
    "    Parameters:\n",
    "    df1 (pd.DataFrame): First DataFrame.\n",
    "    df2 (pd.DataFrame): Second DataFrame.\n",
    "    column (str): Column name on which to perform the test.\n",
    "\n",
    "    Returns:\n",
    "    ks_stat (float): The KS test statistic.\n",
    "    ks_p_value (float): The p-value from the KS test.\n",
    "    \"\"\"\n",
    "    ks_stat, ks_p_value = ks_2samp(df1[column], df2[column])\n",
    "    return ks_stat, ks_p_value\n",
    "\n",
    "# 2. Chi-Square Test\n",
    "def chi_square_test(df1, df2, column):\n",
    "    \"\"\"\n",
    "    Perform the Chi-Square test to compare the categorical distributions between two DataFrames.\n",
    "\n",
    "    Parameters:\n",
    "    df1 (pd.DataFrame): First DataFrame.\n",
    "    df2 (pd.DataFrame): Second DataFrame.\n",
    "    column (str): Column name with categorical data.\n",
    "\n",
    "    Returns:\n",
    "    chi2_stat (float): The Chi-Square statistic.\n",
    "    p_val (float): The p-value from the Chi-Square test.\n",
    "    \"\"\"\n",
    "    cont_table = pd.crosstab(df1[column], df2[column])\n",
    "    chi2_stat, p_val, _, _ = chi2_contingency(cont_table)\n",
    "    return chi2_stat, p_val\n",
    "\n",
    "# 3. Mean Absolute Error (MAE)\n",
    "def calculate_mae(df1, df2, column):\n",
    "    \"\"\"\n",
    "    Calculate the Mean Absolute Error between two sets of values from the DataFrames.\n",
    "\n",
    "    Parameters:\n",
    "    df1 (pd.DataFrame): First DataFrame.\n",
    "    df2 (pd.DataFrame): Second DataFrame.\n",
    "    column (str): Column name with numeric data.\n",
    "\n",
    "    Returns:\n",
    "    mae (float): Mean Absolute Error.\n",
    "    \"\"\"\n",
    "    return mean_absolute_error(df1[column], df2[column])\n",
    "\n",
    "# 4. Root Mean Squared Error (RMSE)\n",
    "def calculate_rmse(df1, df2, column):\n",
    "    \"\"\"\n",
    "    Calculate the Root Mean Squared Error between two sets of values from the DataFrames.\n",
    "\n",
    "    Parameters:\n",
    "    df1 (pd.DataFrame): First DataFrame.\n",
    "    df2 (pd.DataFrame): Second DataFrame.\n",
    "    column (str): Column name with numeric data.\n",
    "\n",
    "    Returns:\n",
    "    rmse (float): Root Mean Squared Error.\n",
    "    \"\"\"\n",
    "    return np.sqrt(mean_squared_error(df1[column], df2[column]))\n",
    "\n",
    "# 5. Transition Matrix considering missing categories\n",
    "def transition_matrix(df1, df2, category_column):\n",
    "    \"\"\"\n",
    "    Create a transition matrix showing how categories change between two time periods, considering missing categories.\n",
    "\n",
    "    Parameters:\n",
    "    df1 (pd.DataFrame): First DataFrame containing 'asset_id' and category_column.\n",
    "    df2 (pd.DataFrame): Second DataFrame containing 'asset_id' and category_column.\n",
    "    category_column (str): Column name containing the categorical data.\n",
    "\n",
    "    Returns:\n",
    "    transition_matrix (pd.DataFrame): A DataFrame representing the transition matrix, normalized by row.\n",
    "    \"\"\"\n",
    "    merged_df = pd.merge(df1[['asset_id', category_column]], \n",
    "                         df2[['asset_id', category_column]], \n",
    "                         on='asset_id', \n",
    "                         suffixes=('_t1', '_t2'),\n",
    "                         how='outer')\n",
    "    \n",
    "    # Replace missing values with 'Missing' to account for entries that do not exist in both DataFrames\n",
    "    merged_df.fillna('Missing', inplace=True)\n",
    "\n",
    "    # Create transition matrix normalized by row\n",
    "    transition_matrix = pd.crosstab(merged_df[category_column + '_t1'], \n",
    "                                    merged_df[category_column + '_t2'], \n",
    "                                    normalize='index')\n",
    "    return transition_matrix\n",
    "\n",
    "# 6. Percentage transition matrix\n",
    "def percentage_transition(transition_matrix):\n",
    "    \"\"\"\n",
    "    Calculate the percentage representation of each transition in the transition matrix.\n",
    "\n",
    "    Parameters:\n",
    "    transition_matrix (pd.DataFrame): A transition matrix DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    transition_percentages (pd.DataFrame): A DataFrame representing transition percentages per row.\n",
    "    \"\"\"\n",
    "    transition_percentages = transition_matrix.apply(lambda x: x / x.sum(), axis=1)\n",
    "    return transition_percentages\n",
    "\n",
    "# --- Example usage of the functions ---\n",
    "\n",
    "# Assuming df1 and df2 are your DataFrames and 'value' and 'category' are the respective columns\n",
    "ks_stat, ks_p_value = kolmogorov_smirnov_test(df1, df2, 'value')\n",
    "chi2_stat, chi2_p_value = chi_square_test(df1, df2, 'category')\n",
    "mae = calculate_mae(df1, df2, 'value')\n",
    "rmse = calculate_rmse(df1, df2, 'value')\n",
    "\n",
    "# Create transition matrix and calculate percentages\n",
    "trans_matrix = transition_matrix(df1, df2, 'category')\n",
    "transition_percentages = percentage_transition(trans_matrix)\n",
    "\n",
    "# Output results\n",
    "print(f\"Kolmogorov-Smirnov test: Statistic={ks_stat}, p-value={ks_p_value}\")\n",
    "print(f\"Chi-Square test: Statistic={chi2_stat}, p-value={chi2_p_value}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(\"Transition Matrix:\")\n",
    "print(trans_matrix)\n",
    "print(\"Transition Percentages per row:\")\n",
    "print(transition_percentages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56dfe1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "# 1. Kolmogorov-Smirnov Distance Plot (CDFs) with flexible plot size\n",
    "def plot_ks_distance(df1, df2, column, figsize=(10, 6)):\n",
    "    \"\"\"\n",
    "    Plot the CDFs of two datasets and show the Kolmogorov-Smirnov distance.\n",
    "    \n",
    "    Parameters:\n",
    "    df1 (pd.DataFrame): First DataFrame.\n",
    "    df2 (pd.DataFrame): Second DataFrame.\n",
    "    column (str): Column name with numerical data to compare.\n",
    "    figsize (tuple): Size of the plot (default is (10, 6)).\n",
    "    \n",
    "    Returns:\n",
    "    None: Displays the plot.\n",
    "    \"\"\"\n",
    "    # Sort values\n",
    "    data1_sorted = np.sort(df1[column])\n",
    "    data2_sorted = np.sort(df2[column])\n",
    "\n",
    "    # CDFs\n",
    "    cdf1 = np.arange(1, len(data1_sorted)+1) / len(data1_sorted)\n",
    "    cdf2 = np.arange(1, len(data2_sorted)+1) / len(data2_sorted)\n",
    "\n",
    "    # Plot CDFs\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.step(data1_sorted, cdf1, label='Initial Data', color='blue')\n",
    "    plt.step(data2_sorted, cdf2, label='Future Data', color='green')\n",
    "    plt.title(f'Kolmogorov-Smirnov Distance for {column}')\n",
    "    plt.xlabel(f'{column}')\n",
    "    plt.ylabel('CDF')\n",
    "    plt.legend(loc='best')\n",
    "\n",
    "    # Kolmogorov-Smirnov distance\n",
    "    ks_stat, _ = ks_2samp(df1[column], df2[column])\n",
    "    plt.text(0.1, 0.9, f'KS Distance = {ks_stat:.4f}', transform=plt.gca().transAxes, fontsize=12)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# 2. Histograms or KDEs with customizable bins and plot size\n",
    "def plot_distribution_comparison(df1, df2, column, plot_type='hist', bins=30, figsize=(10, 6)):\n",
    "    \"\"\"\n",
    "    Plot a comparison of distributions using either histograms or KDEs.\n",
    "\n",
    "    Parameters:\n",
    "    df1 (pd.DataFrame): First DataFrame.\n",
    "    df2 (pd.DataFrame): Second DataFrame.\n",
    "    column (str): Column name with numerical data.\n",
    "    plot_type (str): Type of plot ('hist' for histogram, 'kde' for Kernel Density Estimate).\n",
    "    bins (int): Number of bins for histogram (default is 30).\n",
    "    figsize (tuple): Size of the plot (default is (10, 6)).\n",
    "\n",
    "    Returns:\n",
    "    None: Displays the plot.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    if plot_type == 'hist':\n",
    "        plt.hist(df1[column], bins=bins, alpha=0.5, label='Initial Data', color='blue', density=True)\n",
    "        plt.hist(df2[column], bins=bins, alpha=0.5, label='Future Data', color='green', density=True)\n",
    "    elif plot_type == 'kde':\n",
    "        df1[column].plot(kind='kde', label='Initial Data', color='blue', linewidth=2)\n",
    "        df2[column].plot(kind='kde', label='Future Data', color='green', linewidth=2)\n",
    "\n",
    "    plt.title(f'Distribution Comparison for {column}')\n",
    "    plt.xlabel(f'{column}')\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend(loc='best')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# 3. Boxplot comparison with customizable plot size\n",
    "def plot_boxplot_comparison(df1, df2, column, figsize=(10, 6)):\n",
    "    \"\"\"\n",
    "    Plot a boxplot comparison for a numerical column across two datasets.\n",
    "\n",
    "    Parameters:\n",
    "    df1 (pd.DataFrame): First DataFrame.\n",
    "    df2 (pd.DataFrame): Second DataFrame.\n",
    "    column (str): Column name with numerical data.\n",
    "    figsize (tuple): Size of the plot (default is (10, 6)).\n",
    "\n",
    "    Returns:\n",
    "    None: Displays the boxplot.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    data = [df1[column], df2[column]]\n",
    "    plt.boxplot(data, labels=['Initial Data', 'Future Data'], patch_artist=True,\n",
    "                boxprops=dict(facecolor='lightblue'), medianprops=dict(color='red'))\n",
    "    \n",
    "    plt.title(f'Boxplot Comparison for {column}')\n",
    "    plt.ylabel(f'{column}')\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ace50cb4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-d71846ade0ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;31m# Example usage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;31m# Assuming df1 and df2 are your DataFrames and 'city' is the categorical column you want to compare\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[0mplot_ks_distance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'price'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Custom plot size for KS Distance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[0mplot_distribution_comparison\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'price'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'hist'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Custom bins for histogram\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[0mplot_boxplot_comparison\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'price'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Custom plot size for boxplot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df1' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_categorical_comparison(df1, df2, column, figsize=(10, 6)):\n",
    "    \"\"\"\n",
    "    Plot a comparison of categorical data proportions between two datasets.\n",
    "\n",
    "    Parameters:\n",
    "    df1 (pd.DataFrame): First DataFrame.\n",
    "    df2 (pd.DataFrame): Second DataFrame.\n",
    "    column (str): Column name with categorical data.\n",
    "    figsize (tuple): Size of the plot (default is (10, 6)).\n",
    "\n",
    "    Returns:\n",
    "    None: Displays the bar plot.\n",
    "    \"\"\"\n",
    "    # Calculate proportions in both DataFrames\n",
    "    prop1 = df1[column].value_counts(normalize=True)\n",
    "    prop2 = df2[column].value_counts(normalize=True)\n",
    "\n",
    "    # Create a DataFrame to hold both proportions\n",
    "    comparison_df = pd.DataFrame({'Initial Data': prop1, 'Future Data': prop2}).fillna(0)\n",
    "\n",
    "    # Plot the comparison\n",
    "    comparison_df.plot(kind='bar', figsize=figsize)\n",
    "    plt.title(f'Categorical Comparison for {column}')\n",
    "    plt.xlabel(f'{column}')\n",
    "    plt.ylabel('Proportion')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(loc='best')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "# Assuming df1 and df2 are your DataFrames and 'city' is the categorical column you want to compare\n",
    "plot_ks_distance(df1, df2, 'price', figsize=(12, 8))  # Custom plot size for KS Distance\n",
    "plot_distribution_comparison(df1, df2, 'price', plot_type='hist', bins=40)  # Custom bins for histogram\n",
    "plot_boxplot_comparison(df1, df2, 'price', figsize=(8, 6))  # Custom plot size for boxplot\n",
    "plot_categorical_comparison(df1, df2, 'city', figsize=(12, 6))  # Categorical comparison plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b624cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def rename_and_validate_dataframes(df1, df2, column_mapping_df1, column_mapping_df2, dtype_mapping):\n",
    "    \"\"\"\n",
    "    Renames columns in two DataFrames based on provided dictionaries and checks if the column data types match\n",
    "    the expected types. If the data types don't match, it attempts to cast the columns and raises a flag if unable.\n",
    "    The original column is kept if casting fails, and a message is printed indicating which columns need to be reviewed.\n",
    "\n",
    "    Parameters:\n",
    "    df1 (pd.DataFrame): First DataFrame to be processed.\n",
    "    df2 (pd.DataFrame): Second DataFrame to be processed.\n",
    "    column_mapping_df1 (dict): Dictionary with keys as current column names in df1 and values as consolidated column names.\n",
    "    column_mapping_df2 (dict): Dictionary with keys as current column names in df2 and values as consolidated column names.\n",
    "    dtype_mapping (dict): Dictionary specifying the expected data type for each consolidated column name.\n",
    "\n",
    "    Returns:\n",
    "    df1_renamed (pd.DataFrame): First DataFrame with renamed columns and validated types.\n",
    "    df2_renamed (pd.DataFrame): Second DataFrame with renamed columns and validated types.\n",
    "    invalid_columns (list): List of columns that could not be casted to the expected data type.\n",
    "    \"\"\"\n",
    "    # Rename columns based on separate mappings for each DataFrame\n",
    "    df1_renamed = df1.rename(columns=column_mapping_df1)\n",
    "    df2_renamed = df2.rename(columns=column_mapping_df2)\n",
    "    \n",
    "    # List to track columns that could not be cast\n",
    "    invalid_columns = []\n",
    "\n",
    "    # Iterate over dtype_mapping to check and cast types\n",
    "    for column, expected_dtype in dtype_mapping.items():\n",
    "        if column in df1_renamed.columns:\n",
    "            # Check if df1 column can be cast to the expected dtype\n",
    "            if not pd.api.types.is_dtype_equal(df1_renamed[column].dtype, expected_dtype):\n",
    "                try:\n",
    "                    df1_renamed[column] = df1_renamed[column].astype(expected_dtype)\n",
    "                except (ValueError, TypeError):\n",
    "                    # If casting fails, keep the original column and flag it\n",
    "                    invalid_columns.append((column, 'df1', df1_renamed[column].dtype))\n",
    "                    print(f\"Column '{column}' in df1 has type {df1_renamed[column].dtype} and couldn't be cast to {expected_dtype}.\")\n",
    "        \n",
    "        if column in df2_renamed.columns:\n",
    "            # Check if df2 column can be cast to the expected dtype\n",
    "            if not pd.api.types.is_dtype_equal(df2_renamed[column].dtype, expected_dtype):\n",
    "                try:\n",
    "                    df2_renamed[column] = df2_renamed[column].astype(expected_dtype)\n",
    "                except (ValueError, TypeError):\n",
    "                    # If casting fails, keep the original column and flag it\n",
    "                    invalid_columns.append((column, 'df2', df2_renamed[column].dtype))\n",
    "                    print(f\"Column '{column}' in df2 has type {df2_renamed[column].dtype} and couldn't be cast to {expected_dtype}.\")\n",
    "\n",
    "    return df1_renamed, df2_renamed, invalid_columns\n",
    "\n",
    "# Example usage\n",
    "# Assuming df1 and df2 are the two DataFrames you want to process\n",
    "# column_mapping_df1 maps current column names in df1 to the desired consolidated names\n",
    "column_mapping_df1 = {\n",
    "    'asset_price': 'price',\n",
    "    'asset_area': 'area',\n",
    "    'city_name': 'city',\n",
    "    # Add more mappings as needed\n",
    "}\n",
    "\n",
    "# column_mapping_df2 maps current column names in df2 to the desired consolidated names\n",
    "column_mapping_df2 = {\n",
    "    'price_asset': 'price',\n",
    "    'area_asset': 'area',\n",
    "    'location_city': 'city',\n",
    "    # Add more mappings as needed\n",
    "}\n",
    "\n",
    "# dtype_mapping specifies the expected data type for each consolidated column\n",
    "dtype_mapping = {\n",
    "    'price': 'float64',\n",
    "    'area': 'float64',\n",
    "    'city': 'object',  # 'object' is the dtype for strings in pandas\n",
    "    # Add more expected types as needed\n",
    "}\n",
    "\n",
    "df1_renamed, df2_renamed, invalid_columns = rename_and_validate_dataframes(df1, df2, column_mapping_df1, column_mapping_df2, dtype_mapping)\n",
    "\n",
    "# Output results\n",
    "if invalid_columns:\n",
    "    print(\"The following columns could not be cast to the expected data type and were left as is:\")\n",
    "    for col, df_name, current_dtype in invalid_columns:\n",
    "        print(f\"Column '{col}' in {df_name} has type {current_dtype} and couldn't be cast to {dtype_mapping[col]}.\")\n",
    "else:\n",
    "    print(\"All columns have been successfully cast to the expected data types.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3290a4d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
